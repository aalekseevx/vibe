{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.302654Z",
     "start_time": "2025-05-06T18:41:15.299294Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Hardcoded experiments (without path prefix)\n",
    "experiments = [\n",
    "    \"TestVnetRunnerABR/VariableAvailableCapacitySingleFlow\",\n",
    "]\n",
    "\n",
    "# Base path for experiment data\n",
    "base_path = \"vnet/data\"\n",
    "\n",
    "# Hardcoded config path\n",
    "config_path = \"vnet/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config_loader",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.382690Z",
     "start_time": "2025-05-06T18:41:15.376069Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    \"\"\"Load the configuration file and return test cases as a dictionary.\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Convert test cases to a dictionary with name as key\n",
    "    test_cases = {}\n",
    "    for test_case in config.get('test_cases', []):\n",
    "        if 'name' in test_case:\n",
    "            test_cases[test_case['name']] = test_case\n",
    "    \n",
    "    return test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "path_characteristics_extractor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.382690Z",
     "start_time": "2025-05-06T18:41:15.376069Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_path_characteristics(test_case):\n",
    "    \"\"\"Extract path characteristics from the test case configuration.\"\"\"\n",
    "    path_char = test_case.get('path_characteristic', {})\n",
    "    phases = path_char.get('phases', [])\n",
    "    \n",
    "    if not phases:\n",
    "        return None\n",
    "    \n",
    "    # Convert phases to a time series\n",
    "    time_points = []\n",
    "    capacity_points = []\n",
    "    \n",
    "    current_time = 0\n",
    "    \n",
    "    for phase in phases:\n",
    "        # Extract duration in seconds\n",
    "        duration_str = phase.get('duration', '0s')\n",
    "        if duration_str.endswith('s'):\n",
    "            duration = int(duration_str[:-1])\n",
    "        else:\n",
    "            duration = int(duration_str)\n",
    "        \n",
    "        # Extract capacity in bits per second\n",
    "        capacity = phase.get('capacity', 0)\n",
    "        \n",
    "        # Add start point of this phase\n",
    "        time_points.append(current_time)\n",
    "        capacity_points.append(capacity / 1000)  # Convert to kbps\n",
    "        \n",
    "        # Add end point of this phase\n",
    "        current_time += duration\n",
    "        time_points.append(current_time)\n",
    "        capacity_points.append(capacity / 1000)  # Convert to kbps\n",
    "    \n",
    "    return {\n",
    "        'time': time_points,\n",
    "        'capacity_kbps': capacity_points\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2784fbf17a8bbbe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.382690Z",
     "start_time": "2025-05-06T18:41:15.376069Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_experiments_data(experiments, base_path):\n",
    "    \"\"\"Load experiment data from log files.\"\"\"\n",
    "    experiment_data = {}\n",
    "\n",
    "    for experiment in experiments:\n",
    "        # Construct full path\n",
    "        exp_path = Path(base_path) / experiment\n",
    "        flows = {}\n",
    "\n",
    "        for log_file in exp_path.glob(\"*.log\"):\n",
    "            parts = log_file.stem.split(\"_\", 1)\n",
    "            if len(parts) != 2:\n",
    "                continue  # skip malformed names\n",
    "            flow_id, log_type = parts\n",
    "            flow_id = int(flow_id)\n",
    "\n",
    "            if flow_id not in flows:\n",
    "                flows[flow_id] = {}\n",
    "            flows[flow_id][log_type] = log_file\n",
    "\n",
    "        # Parse logs per flow\n",
    "        experiment_data[experiment] = {}\n",
    "        for flow_id, logs in flows.items():\n",
    "            flow_data = {}\n",
    "\n",
    "            if \"cc\" in logs:\n",
    "                cc_log = pd.read_csv(logs[\"cc\"], header=None, names=[\"time\", \"target_bitrate\"])\n",
    "                cc_log[\"time\"] = pd.to_datetime(cc_log[\"time\"], unit=\"ms\")\n",
    "                flow_data[\"cc_log\"] = cc_log\n",
    "\n",
    "            for side in [\"sender\", \"receiver\"]:\n",
    "                for kind in [\"rtp\", \"rtcp\"]:\n",
    "                    key = f\"{side}_{kind}\"\n",
    "                    if key in logs:\n",
    "                        if kind == \"rtp\":\n",
    "                            df = pd.read_csv(logs[key], header=None, names=[\n",
    "                                \"time\", \"payload_type\", \"ssrc\", \"seq\", \"timestamp\",\n",
    "                                \"marker\", \"size\", \"twcc\", \"unwrapped_seq\"\n",
    "                            ])\n",
    "                            df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"ms\")\n",
    "                        else:\n",
    "                            df = pd.read_csv(logs[key], header=None, names=[\"time\", \"size\"])\n",
    "                            df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"ms\")\n",
    "                        flow_data[key] = df\n",
    "\n",
    "            experiment_data[experiment][flow_id] = flow_data\n",
    "\n",
    "    return experiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e250a7f18c3b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.451633Z",
     "start_time": "2025-05-06T18:41:15.447484Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_bitrates(experiment_data, window_ms=500):\n",
    "    \"\"\"Compute bitrates for all experiments.\"\"\"\n",
    "    for exp_name, flows in experiment_data.items():\n",
    "        for flow_id, data in flows.items():\n",
    "            if \"sender_rtp\" in data:\n",
    "                df = data[\"sender_rtp\"]\n",
    "                df[\"time_bin\"] = df[\"time\"].dt.floor(f\"{window_ms}ms\")\n",
    "                bitrate_df = df.groupby(\"time_bin\")[\"size\"].sum().reset_index()\n",
    "                bitrate_df[\"bitrate_kbps\"] = (bitrate_df[\"size\"] * 8) / (window_ms / 1000) / 1000\n",
    "                data[\"bitrate\"] = bitrate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lost_packets_calculator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.451633Z",
     "start_time": "2025-05-06T18:41:15.447484Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_lost_packets(experiment_data):\n",
    "    \"\"\"Compute cumulative lost packets for all experiments.\"\"\"\n",
    "    for exp_name, flows in experiment_data.items():\n",
    "        for flow_id, data in flows.items():\n",
    "            if \"receiver_rtp\" in data:\n",
    "                df = data[\"receiver_rtp\"]\n",
    "                \n",
    "                # Sort by time to ensure correct cumulative calculation\n",
    "                df = df.sort_values(by=\"time\")\n",
    "                \n",
    "                # Calculate min unwrapped sequence number\n",
    "                min_seq = df[\"unwrapped_seq\"].min()\n",
    "                \n",
    "                # Calculate expected packets at each point\n",
    "                df[\"expected_packets\"] = df[\"unwrapped_seq\"] - min_seq + 1\n",
    "                \n",
    "                # Calculate received packets (cumulative count)\n",
    "                df[\"received_packets\"] = np.arange(1, len(df) + 1)\n",
    "                \n",
    "                # Calculate lost packets\n",
    "                df[\"lost_packets\"] = df[\"expected_packets\"] - df[\"received_packets\"]\n",
    "                \n",
    "                # Store the result\n",
    "                data[\"lost_packets\"] = df[[\"time\", \"lost_packets\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jitter_calculator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.451633Z",
     "start_time": "2025-05-06T18:41:15.447484Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_interarrival_jitter(experiment_data):\n",
    "    \"\"\"Compute interarrival jitter according to RFC 3550.\n",
    "    \n",
    "    The interarrival jitter is defined as the mean deviation of the difference\n",
    "    in packet spacing at the receiver compared to the sender for a pair of packets.\n",
    "    \n",
    "    Formula: J(i) = J(i-1) + (|D(i-1,i)| - J(i-1))/16\n",
    "    where D(i-1,i) = (Ri - Ri-1) - (Si - Si-1) = (Ri - Si) - (Ri-1 - Si-1)\n",
    "    \n",
    "    Ri is the time of arrival in RTP timestamp units for packet i\n",
    "    Si is the RTP timestamp from packet i\n",
    "    \"\"\"\n",
    "    for exp_name, flows in experiment_data.items():\n",
    "        for flow_id, data in flows.items():\n",
    "            if \"receiver_rtp\" in data:\n",
    "                df = data[\"receiver_rtp\"]\n",
    "                \n",
    "                # Sort by time to ensure correct sequential processing\n",
    "                df = df.sort_values(by=\"time\")\n",
    "                \n",
    "                # Convert arrival time to milliseconds since first packet\n",
    "                first_arrival = df[\"time\"].min()\n",
    "                df[\"arrival_ms\"] = (df[\"time\"] - first_arrival).dt.total_seconds() * 1000\n",
    "                \n",
    "                # Initialize jitter array\n",
    "                jitter = np.zeros(len(df))\n",
    "                \n",
    "                # Calculate jitter for each packet (starting from the second one)\n",
    "                for i in range(1, len(df)):\n",
    "                    # Calculate D: difference in relative transit times\n",
    "                    # D(i-1,i) = (Ri - Ri-1) - (Si - Si-1) = (Ri - Si) - (Ri-1 - Si-1)\n",
    "                    arrival_diff = df.iloc[i][\"arrival_ms\"] - df.iloc[i-1][\"arrival_ms\"]\n",
    "                    timestamp_diff = df.iloc[i][\"timestamp\"] - df.iloc[i-1][\"timestamp\"]\n",
    "                    \n",
    "                    # Convert timestamp diff to same units as arrival (ms)\n",
    "                    # Assuming RTP timestamp is in the same timebase\n",
    "                    # This is a simplification - in reality, we would need to know the clock rate\n",
    "                    timestamp_diff_ms = timestamp_diff / 90  # Assuming 90kHz clock rate for video\n",
    "                    \n",
    "                    D = arrival_diff - timestamp_diff_ms\n",
    "                    \n",
    "                    # Update jitter using the formula J(i) = J(i-1) + (|D(i-1,i)| - J(i-1))/16\n",
    "                    jitter[i] = jitter[i-1] + (abs(D) - jitter[i-1]) / 16\n",
    "                \n",
    "                # Create a DataFrame with time and jitter\n",
    "                jitter_df = pd.DataFrame({\n",
    "                    \"time\": df[\"time\"],\n",
    "                    \"jitter\": jitter\n",
    "                })\n",
    "                \n",
    "                # Store the result\n",
    "                data[\"jitter\"] = jitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33af1acbab7513e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.524330Z",
     "start_time": "2025-05-06T18:41:15.519257Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_experiment_results(experiment_data, path_characteristics_map):\n",
    "    \"\"\"Plot bitrates, path characteristics, lost packets, and jitter for all experiments.\"\"\"\n",
    "    for exp_name, flows in experiment_data.items():\n",
    "        # Create a figure with three subplots (bitrate, lost packets, and jitter)\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15), sharex=True)\n",
    "        fig.suptitle(f\"Experiment Results - {exp_name}\", fontsize=16)\n",
    "        \n",
    "        # Setup first subplot for bitrate\n",
    "        ax1.set_title(\"Bitrate Utilization\")\n",
    "        ax1.set_ylabel(\"Bitrate (kbps)\")\n",
    "        \n",
    "        # Setup second subplot for lost packets\n",
    "        ax2.set_title(\"Cumulative Lost Packets\")\n",
    "        ax2.set_ylabel(\"Lost Packets Count\")\n",
    "        \n",
    "        # Setup third subplot for jitter\n",
    "        ax3.set_title(\"Interarrival Jitter (RFC 3550)\")\n",
    "        ax3.set_xlabel(\"Time\")\n",
    "        ax3.set_ylabel(\"Jitter (ms)\")\n",
    "        \n",
    "        colors = plt.colormaps.get_cmap('tab10').colors\n",
    "\n",
    "        # Plot path characteristics if available for this experiment\n",
    "        path_characteristics = path_characteristics_map.get(exp_name)\n",
    "        if path_characteristics:\n",
    "            # Get the start time from the first flow's data\n",
    "            start_time = None\n",
    "            for flow_id, data in flows.items():\n",
    "                if \"sender_rtp\" in data:\n",
    "                    start_time = data[\"sender_rtp\"][\"time\"].min()\n",
    "                    break\n",
    "            \n",
    "            if start_time is not None:\n",
    "                # Convert seconds to datetime\n",
    "                time_points = [start_time + timedelta(seconds=t) for t in path_characteristics['time']]\n",
    "                ax1.plot(time_points, path_characteristics['capacity_kbps'], \n",
    "                        label=\"Path Capacity\", color='black', linestyle='-.', linewidth=2)\n",
    "\n",
    "        for i, (flow_id, data) in enumerate(flows.items()):\n",
    "            color = colors[i % len(colors)]\n",
    "            label = f\"Flow {flow_id}\"\n",
    "\n",
    "            # Plot RTP bitrate on first subplot\n",
    "            if \"bitrate\" in data:\n",
    "                df = data[\"bitrate\"]\n",
    "                ax1.plot(df[\"time_bin\"], df[\"bitrate_kbps\"], label=f\"{label} RTP\",\n",
    "                        color=color, linestyle='-')\n",
    "\n",
    "            # Plot CC target on first subplot\n",
    "            if \"cc_log\" in data:\n",
    "                cc = data[\"cc_log\"]\n",
    "                ax1.plot(cc[\"time\"], cc[\"target_bitrate\"] / 1000, label=f\"{label} Target\",\n",
    "                        color=color, linestyle='--')\n",
    "                \n",
    "            # Plot lost packets on second subplot\n",
    "            if \"lost_packets\" in data:\n",
    "                lost = data[\"lost_packets\"]\n",
    "                ax2.plot(lost[\"time\"], lost[\"lost_packets\"], label=f\"{label} Lost Packets\",\n",
    "                        color=color, linestyle='-')\n",
    "                \n",
    "            # Plot jitter on third subplot\n",
    "            if \"jitter\" in data:\n",
    "                jitter = data[\"jitter\"]\n",
    "                ax3.plot(jitter[\"time\"], jitter[\"jitter\"], label=f\"{label} Jitter\",\n",
    "                        color=color, linestyle='-')\n",
    "\n",
    "        # Add legends\n",
    "        ax1.legend()\n",
    "        ax2.legend()\n",
    "        ax3.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d2000b81e3d0c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:15.866085Z",
     "start_time": "2025-05-06T18:41:15.586523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the experiment data\n",
    "experiment_data = load_experiments_data(experiments, base_path)\n",
    "\n",
    "# Compute bitrates, lost packets, and jitter\n",
    "compute_bitrates(experiment_data)\n",
    "compute_lost_packets(experiment_data)\n",
    "compute_interarrival_jitter(experiment_data)\n",
    "\n",
    "# Load test cases from the configuration as a dictionary\n",
    "test_cases = load_config(config_path)\n",
    "\n",
    "# Extract path characteristics for each experiment\n",
    "path_characteristics_map = {}\n",
    "for experiment in experiments:\n",
    "    # This will raise KeyError if experiment is not in test_cases\n",
    "    test_case = test_cases[experiment]\n",
    "    path_characteristics_map[experiment] = extract_path_characteristics(test_case)\n",
    "\n",
    "# Plot the data with path characteristics, lost packets, and jitter\n",
    "plot_experiment_results(experiment_data, path_characteristics_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
